{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.utils.spectrogram_normalizer import SpectrogramNormalizer\n",
    "from src.data.utils.label_normalizer import LabelNormalizer\n",
    "from src.data.datasets.melody_dataset import MelodyDataset\n",
    "from src.data.datasets.audio_dataset import AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slicing audio: 100%|██████████| 103/103 [00:20<00:00,  4.99it/s]\n",
      "Preprocessing audio:   0%|          | 0/1179 [00:00<?, ?it/s]d:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\noisereduce\\torchgate\\torchgate.py:180: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ..\\aten\\src\\ATen\\native\\Convolution.cpp:1009.)\n",
      "  conv1d(\n",
      "Preprocessing audio: 100%|██████████| 1179/1179 [00:14<00:00, 79.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AudioDataset.from_path(\"../datasets/melody_extraction/processed/train\")\n",
    "pipeline = train_dataset.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:08<00:00, 11.66it/s]\n"
     ]
    }
   ],
   "source": [
    "spectrograms = []\n",
    "\n",
    "for a in tqdm(train_dataset.audio):\n",
    "    \n",
    "    audio_copy = deepcopy(a)\n",
    "    audio_copy.trim_silence()\n",
    "    audio_copy = pipeline._preprocess_audio(audio_copy)\n",
    "\n",
    "    spectrogram = pipeline._get_spectrogram(audio_copy)\n",
    "    spectrogram = pipeline.amplitude_to_db(spectrogram.spectrogram)\n",
    "    spectrogram = torch.nn.functional.interpolate(\n",
    "        spectrogram.unsqueeze(0),\n",
    "        size=(128, 256),\n",
    "        mode='bilinear',\n",
    "        align_corners=True\n",
    "    ).squeeze(0)\n",
    "    \n",
    "    spectrograms.append(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating mean and std: 100%|██████████| 4/4 [00:02<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вычисленное среднее: 8.240909576416016\n",
      "Вычисленное стандартное отклонение: 15.86678615808288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating mean and std: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее после нормализации: 2.307961999292729e-08\n",
      "Стандартное отклонение после нормализации: 1.0000000096663868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalizer1 = SpectrogramNormalizer()\n",
    "normalizer1.fit(spectrograms)\n",
    "\n",
    "print(f\"Вычисленное среднее: {normalizer1.mean}\")\n",
    "print(f\"Вычисленное стандартное отклонение: {normalizer1.std}\")\n",
    "\n",
    "normalizer2 = SpectrogramNormalizer(\n",
    "    mean=normalizer1.mean,\n",
    "    std=normalizer1.std\n",
    ")\n",
    "normalizer2.fit(\n",
    "    spectrograms=[\n",
    "        normalizer1.transform(spectrogram)\n",
    "        for spectrogram in spectrograms\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Среднее после нормализации: {normalizer2.mean}\")\n",
    "print(f\"Стандартное отклонение после нормализации: {normalizer2.std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slicing audio and melody: 100%|██████████| 103/103 [00:08<00:00, 11.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MelodyDataset.from_path(\"../datasets/melody_extraction/processed/train\")\n",
    "pipeline = train_dataset.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [pipeline._get_label(m) for m in train_dataset.sliced_melody]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs_min = 0.0\n",
      "freqs_max = 1567.981689453125\n",
      "durations_min = 0.25\n",
      "durations_max = 10.0\n",
      "seq_len_min = 2\n",
      "seq_len_max = 58\n"
     ]
    }
   ],
   "source": [
    "label_normalizer = LabelNormalizer()\n",
    "label_normalizer.fit_from_labels(labels)\n",
    "\n",
    "print(f\"freqs_min = {label_normalizer.freq_min}\")\n",
    "print(f\"freqs_max = {label_normalizer.freq_max}\")\n",
    "print(f\"durations_min = {label_normalizer.dur_min}\")\n",
    "print(f\"durations_max = {label_normalizer.dur_max}\")\n",
    "print(f\"seq_len_min = {label_normalizer.seq_len_min}\")\n",
    "print(f\"seq_len_max = {label_normalizer.seq_len_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([184.9972, 184.9972, 184.9972, 184.9972,   0.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[42].freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7102, 0.7102, 0.7102, 0.7102, 0.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label_normalizer.transform_label(labels[42])\n",
    "label.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([184.9972, 184.9972, 184.9972, 184.9972,   0.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label_normalizer.inverse_transform_label(label)\n",
    "label.freqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
